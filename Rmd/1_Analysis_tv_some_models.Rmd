---
title: "Data analysis tv"
output: 
    html_document:
      md_extensions: -ascii_identifiers
      toc: true
      toc_depth: 3
      code_folding: hide
---

# Setting{.tabset .tabset-fade .tabset-pills}

- option, package, database setting

## knitr option

```{r reset, include=FALSE}
# 初期化
rm(list = ls())
```

```{r set up, message=FALSE}
# set directory
setwd("~/Desktop/Datacomp2018/") 
# max.print 
options(max.print="20", digits=5)
# Global options
library(knitr)
opts_chunk$set(echo=TRUE,
               cache = FALSE,
	             prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.width = 11)
opts_knit$set(width=75)
```

## packages

```{r package, message=FALSE}
library(tidyverse)
library(summarytools) # summary easily for EDA
library(skimr) 
library(RPostgreSQL)
library(dbplyr)
library(lubridate)
library(ggthemes)
library(ggpmisc)
library(ggforce)
library(scales)
library(doParallel)
library(foreach)
library(DT)
library(gridExtra)
library(xgboost)
library(ggpmisc)
library(Metrics)
# set ggplot theme
theme_set(theme_classic(base_size = 18,base_family = "Helvetica"))
```

## functions

```{r}
source('~/Desktop/DataComp2018/script/function.R')
source('~/Desktop/DataComp2018/script/makedummy.R')
```

## Database connecting 

- 接続情報は, script内で処理する

```{r}
source('~/Desktop/DataComp2018/script/sql_connect.R')
```

## load data

```{r}
# load csv
alltime <- read_csv("~/Desktop/DataComp2018/data/watch_rate.csv") %>% 
  mutate(program_start_time = as_datetime(program_start_time, tz="Asia/Tokyo"))
alltime2 <- read_csv("~/Desktop/DataComp2018/data/watch_rate_pre.csv") %>%
  mutate(program_start_time = as_datetime(program_start_time, tz="Asia/Tokyo"))
```

## load cluster

```{r}
LogCluster <- readRDS("~/Desktop/DataComp2018/data/tmp.rds")
pro_mst <- program %>%
  count(program_code, program_name) %>%
  collect() %>%
  arrange(program_code, desc(n)) %>%
  group_by(program_code) %>%
  #top_n(n = 1, wt = n) %>% 
  dplyr::slice(1) %>% # 各グループの1つのみ残す
  ungroup()

LogCluster1 <- LogCluster %>%
  as.data.frame() %>%
  rownames_to_column(var = "program_code") %>%
  as_tibble() %>%
  gather(topic, value, -program_code) %>%
  left_join(pro_mst, by = "program_code") %>%
  group_by(program_code) %>%
  top_n(1,value) %>% 
  ungroup()
```

# XGBoost

## Preprocess

```{r}
fn2 <- funs(mean, min, max, sd, .args = list(na.rm = TRUE))
# 特徴量作成, 特徴量と視聴率3つを残す
# 平均視聴率と比較するために, 1ヶ月分減らした, alltime2を使用する
alltime2 %>% 
  left_join(program %>% 
              select(station_code,program_start_time,ban_code1,
                     ban_code2,ban_code3,sin_toku,br_format,
                     final_code,program_time,program_code,program_name) %>% 
              dplyr::collect(),
            by = c("station_code","program_start_time")) %>% 
  mutate(Wday = wday(program_start_time) %>% as.factor(),
         #Month = month(program_start_time) %>% as.factor(),
         Hour = hour(program_start_time) %>% as.factor(), 
         ban_code1 = ban_code1 %>% as.factor(),
         ban_code2 = ban_code2 %>% as.factor(),
         ban_code3 = ban_code3 %>% as.factor(),
         station_code = station_code %>% as.factor(),
         br_format = br_format %>% as.factor(),
         final_code = final_code %>% as.factor(),
         sin_toku = sin_toku %>% as.factor()) %>% 
  # select(-c(real_watch,shift_watch,all_watch)) -> tmp # alltime用
  select(-c(pre1,pre2,pre3,pre4, rate1,rate2,rate3,rate4)) %>% 
  arrange(program_start_time) %>% 
  left_join(LogCluster1 %>% 
              select(program_code,topic) %>% 
              mutate(topic = factor(topic)),
            by="program_code") -> tmp
tmp1 <- tmp %>% 
  left_join(tmp %>% 
              filter(program_start_time < "2018-02-01 0:00:00" %>% as.Date(tz = "Asia/Tokyo")) %>% 
              group_by(ban_code1) %>% summarise_at(c("all_watch_rate"),fn2),by = "ban_code1") %>% 
  left_join(tmp %>% 
              filter(program_start_time < "2018-02-01 0:00:00" %>% as.Date(tz = "Asia/Tokyo")) %>% 
              group_by(Hour) %>% summarise_at(c("all_watch_rate"),fn2),by = "Hour")
```

```{r}
train_data <- tmp1 %>% 
  filter(program_start_time < "2018-02-01 0:00:00" %>% as.Date(tz = "Asia/Tokyo")) %>% 
  filter(all_watch_rate %>% is.na() %>% !.)
test_data <- tmp1 %>% 
  filter(program_start_time >= "2018-02-01 0:00:00" %>% as.Date(tz = "Asia/Tokyo")) %>% 
  filter(all_watch_rate %>% is.na() %>% !.)
```

## parameter

```{r}
# xgboost fitting with arbitrary parameters
xgb_params <- list(objective = "reg:linear",
                   # objective = "count:poisson",
                   booster = "gbtree",
                   eval_metric = "rmse",
                   nthread = 8,
                   eta = 0.05,
                   max_depth = 5,
                   min_child_weight = 30,
                   gamma = 0,
                   subsample = 0.85,
                   colsample_bytree = 0.65,
                   alpha = 0,
                   lambda = 0)
```

## model

```{r}
XgboostPred <- function(xgb_params,train_data,test_data){
  # set data
  train <- train_data %>% 
    select(-c(program_start_time,all_watch_rate,mean_rate,program_code,program_name,topic)) %>% 
    data.matrix()
  test <- test_data %>% 
    select(-c(program_start_time,all_watch_rate,mean_rate,program_code,program_name,topic)) %>% 
    data.matrix()
  target <- train_data$all_watch_rate %>% log1p()
  # set seed
  set.seed(831)
  # xgboost cross validation to choice best parameter
  xgb_cv <- 
    xgb.cv(data = xgb.DMatrix(data = train, label = target),
           params = xgb_params,
           missing = NA,
           nfold = 4,
           nrounds = 3000,
           verbose = TRUE,
           prediction = TRUE,                                           # return the prediction using the final model 
           showsd = TRUE,                                               # standard deviation of loss across folds
           stratified = TRUE, 
           print_every_n = 10,
           early_stopping_rounds = 200 )
  # xgboost modeling  
  xgb_model <- 
    xgboost(data = xgb.DMatrix(data = train, label = target),
            params = xgb_params,
            nrounds = xgb_cv$best_iteration, # max number of trees to build
            verbose = TRUE,                                         
            print_every_n = 10,
            early_stopping_rounds = 200 )
  # predict
  pred_train <- predict(xgb_model,train)
  pred_test <- predict(xgb_model,test)
  # predict rmsle
  pred_train <- expm1(predict(xgb_model,train))
  pred_test <- expm1(predict(xgb_model,test))
}
```

```{r}
p1 <- xgb.importance(model = xgb_model) %>% 
  data.frame(.,Feature2 = c("放送時刻(時間)", "チャンネル","放送時間","大分類平均視聴率","放送曜日",
                            "大分類","放送形式","小分類","中分類", "最終回コード","新番特番フラグ")) %>% 
  ggplot(aes(x=reorder(factor(Feature2),Gain),y=Gain)) +
  theme_set(theme_classic(base_size = 18,base_family = "HiraKakuPro-W3")) +
  geom_bar(stat = "identity",fill = "steelblue") +
  coord_flip() +
  labs(x= "特徴量", y="寄与率")
ggsave(file = "~/Desktop/DataComp2018/image/analysis/xgboost変数重要度.png", plot = p1, dpi = 100, width = 10, height = 9.3)
```
## 可視化

- 訓練データに対して,

```{r}
## predict xgboost train data
formula <- y ~ x
data.frame(train_data,pred = pred_train) %>% 
  ggplot(aes(x=all_watch_rate,y=pred)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = formula) +
  stat_poly_eq(formula = formula, parse = TRUE, size=12, color = "magenta3") + 
  theme_set(theme_classic(base_size = 18,base_family = "HiraKakuPro-W3")) 
```

- テストデータに対して

```{r}
# rmse
rmsle(test_data$all_watch_rate,pred_test)
## predict xgboost test data
formula <- y ~ x
p2 <- data.frame(test_data,pred = pred_test) %>% 
  ggplot(aes(x=all_watch_rate,y=pred)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = formula) +
  stat_poly_eq(formula = formula, parse = TRUE, size=12, color = "magenta3") + 
  theme_set(theme_classic(base_size = 18,base_family = "HiraKakuPro-W3")) +
  labs(y ="xgboostによる予測視聴率", x="実際の視聴率", 
       title="テスト期間: 2018/2/1 - 2018/4/1, 標本数: 17466, RMSLE = 0.0054") 
```

```{r}
p <- grid.arrange(p2,p1, layout_matrix = rbind(c(1,1,2)))
ggsave(file = "~/Desktop/DataComp2018/image/analysis/xgboostを予測と変数重要度.png", plot = p, dpi = 100, width = 19.73, height = 9.3)
```

- 従来手法

```{r}
# rmse
rmsle(test_data$all_watch_rate,test_data$mean_rate)
# 従来手法
formula <- y ~ x
p1 <- data.frame(test_data,pred = pred_test) %>% 
  ggplot(aes(x=all_watch_rate,y=mean_rate)) + 
  geom_point() + 
  geom_smooth(method = "lm", formula = formula) +
  stat_poly_eq(formula = formula, parse = TRUE, size=12, color = "magenta3") + 
  theme_set(theme_classic(base_size = 18,base_family = "HiraKakuPro-W3")) +
  labs(y ="従来手法による推定視聴率", x="実際の視聴率", 
       title="テスト期間: 2018/2/1 - 2018/4/1, 標本数: 17466,  RMSLE = 0.0065") 
```

```{r eval=FALSE}
ggsave(file = "~/Desktop/DataComp2018/image/basic/過去4週間分のデータを用いた予測視聴率と総合視聴率の関係性.png", plot = p1, dpi = 100, width = 19.73, height = 9.3)
```

# lm, glm

## Preprocess

```{r}
# 特徴量作成, 特徴量と視聴率3つを残す
# 平均視聴率と比較するために, 1ヶ月分減らした, alltime2を使用する
alltime2 %>% 
  left_join(program %>% 
              select(station_code,program_start_time,ban_code1,
                     ban_code2,ban_code3,sin_toku,br_format,
                     final_code,program_time),
            by = c("station_code","program_start_time")) %>% 
  mutate(Wday = wday(program_start_time) %>% as.factor(),
         # Month = month(program_start_time) %>% as.factor(),
         Hour = hour(program_start_time) %>% as.factor(), 
         ban_code1 = ban_code1 %>% as.factor(),
         ban_code2 = ban_code2 %>% as.factor(),
         ban_code3 = ban_code3 %>% as.factor(),
         station_code = station_code %>% as.factor(),
         br_format = br_format %>% as.factor(),
         final_code = final_code %>% as.factor(),
         sin_toku = sin_toku %>% as.factor()) %>% 
  # select(-c(real_watch,shift_watch,all_watch)) -> tmp # alltime用
  select(-c(pre1,pre2,pre3,pre4, rate1,rate2,rate3,rate4)) %>% 
  arrange(program_start_time) -> tmp
```

```{r}
train_data <- tmp[1:80000,] %>% 
  filter(all_watch_rate %>% is.na() %>% !.)
test_data <- tmp[80001:99598,]
```

## model

### normal 

```{r}
model <- lm(all_watch_rate ~ factor(ban_code1) + factor(ban_code2) + factor(ban_code3) + factor(sin_toku) +
              factor(br_format) + factor(final_code) + program_time + factor(Wday) + factor(Hour), 
            data = train_data)
pred <- predict(model,test_data)
plot(test_data$all_watch_rate,pred)
```

### log normal

```{r}
model <- lm(log1p(all_watch_rate) ~ factor(ban_code1) + factor(ban_code2) + factor(ban_code3) + factor(sin_toku) +
              factor(br_format) + factor(final_code) + program_time + factor(Wday) + factor(Hour), 
            data = train_data)
pred <- predict(model,test_data)
plot(test_data$all_watch_rate,pred)
```

```{r}
model <- glm(all_watch_rate ~ . -program_start_time -all_watch_rate - mean_rate, family = "Gamma"(link = "log"),data = train_data)
pred <- predict(model1,test_data)
plot(test_data$all_watch_rate,pred)
```

## glm

- poisson regrssion

```{r}
model <- glm(all_watch_rate ~ factor(ban_code1) + factor(ban_code2) + factor(ban_code3) + factor(sin_toku) +
            factor(br_format) + factor(final_code) + program_time + factor(Wday) + factor(Hour), 
            family = "poisson",
            data = train_data)

pred <- predict(model1,test_data)
plot(test_data$all_watch_rate,pred)
```


## 階層ベイズモデル
